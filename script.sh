set -e

# import cli cmd functions
source utils/cli_helper.sh


######
## Function that setup an EC2 instance with spark and hadoop running on it
# GLOBALS: 
# 	SUBNETS_1 : The used subnet Id
#   INSTANCE_ID : The generated instance Id  
#   INSTANCE_DNS : The generated EC2 Dns  
# OUTPUTS: 
# 	The instance DNS with all needed setup
######
function setup {
    if [[ -f "backup.txt" ]]; then
        rm -f keypair.pem backup.txt
    fi

    #Setup network security
    create_security_group
    create_keypair

    #Setup EC2 instances
    SUBNETS_1=$(aws ec2 describe-subnets --query "Subnets[0].SubnetId" --output text)    
    
    echo "Launch EC2 instance..."
    INSTANCE_ID=$(launch_ec2_instance $SUBNETS_1 "m4.large")
    #Save the returned InstanceId as backup 
    echo "INSTANCE_ID=\"$INSTANCE_ID\"" >>backup.txt 

    echo "Waiting for instance to complete initialization...."
    aws ec2 wait instance-status-ok --instance-ids $INSTANCE_ID
    INSTANCE_DNS=$(get_ec2_public_dns $INSTANCE_ID)
    #Save the returned InstanceDns as backups
    echo "INSTANCE_DNS=\"$INSTANCE_ID\"" >>backup.txt 
}

######
## Function that compare the execution time of wordcount programm between linux,hadoop and spark
# GLOBALS: 
# 	INSTANCE_DNS : The instance DNS generated by the setup function 
# OUTPUTS: 
# 	Writes execution time results into local files using ssh and files descriptors (stdout/stderr)
######
function comparaison {
    INSTANCE_DNS=ec2-3-236-92-42.compute-1.amazonaws.com
    echo "Waiting for spark to be up and running...."
    #Waiting for spark to be up and running
    while :; do
        # Hit the spark ui on port 8080 to ensure that spark is running
        curl -s --fail -o /dev/null "http://$INSTANCE_DNS:8080" && break
        # Wait 3 seconds before the next try
        sleep 3
    done
    echo "Spark and Hadoop are ready."
    
    #Clean the local env before we start 
    rm -f comparaison/hadoop_linux/output/*.txt comparaison/hadoop_spark/output/*.txt

    #Upload needeed files on the EC2 instance
    scp -i keypair.pem comparaison/hadoop_linux/input/pg4300.txt ubuntu@$INSTANCE_DNS:/home/ubuntu

    #Measure the execution time of wordCount with linux commands using the Ulysses file
    ssh -i keypair.pem ubuntu@$INSTANCE_DNS  'echo "pg4300.txt" 1>&2 | { time -p cat /home/ubuntu/pg4300.txt |tr " " "\n" | sort | uniq -c > linux.logs ; }' 2>> comparaison/hadoop_linux/output/linux_time.txt   
    #Measure the execution time of wordCount on hadoop using the Ulysses file
    ssh -i keypair.pem ubuntu@$INSTANCE_DNS 'bash -s' < comparaison/hadoop_linux/run_hadoop.sh 2>> comparaison/hadoop_linux/output/hadoop_time.txt

    #Measure the execution time of running wordCount 3 times on hadoop using the dataset    
    ssh -i keypair.pem ubuntu@$INSTANCE_DNS 'bash -s' < comparaison/hadoop_spark/run_hadoop.sh 2>> comparaison/hadoop_spark/output/hadoop_time.txt
    #Measure the execution time of running wordCount 3 times on spark using the dataset
    ssh -i keypair.pem ubuntu@$INSTANCE_DNS 'bash -s' < comparaison/hadoop_spark/run_spark.sh 2>> comparaison/hadoop_spark/output/spark_time.txt
}

######
## Function that display the execution time resuts using plotly library 
# OUTPUTS: 
# 	Display dataframes and graphs with collected metrics from the comparaison function
######
function visualisation() {
    # Ulysses metrics path
    local ulysses_linux_metrics=/comparaison/hadoop_linux/output/linux_time.txt
    local ulysses_hadoop_metrics=/comparaison/hadoop_linux/output/hadoop_time.txt
    # datset metrics path
    local dataset_hadoop_metrics=/comparaison/hadoop_spark/output/hadoop_time.txt
    local dataset_spark_metrics=/comparaison/hadoop_spark/output/spark_time.txt

    # Compare linux vs hadoop metrcis
    python3 visualization/display_results.py $ulysses_linux_metrics $ulysses_hadoop_metrics
    
    # Compare hadoop vs spark metrcis
    python3 visualization/display_results.py $dataset_hadoop_metrics $dataset_spark_metrics
}

######
## Function that wipe all the setup on AWS
# OUTPUTS: 
# 	Terminate the instance 
#   Delete the keypair
#   Delete the security group 
######
function wipe {

    source backup.txt

    ## Terminate the ec2 instances
    if [[ -n "${INSTANCE_ID}" ]]; then
        echo "Terminate the ec2 instance..."
        aws ec2 terminate-instances --instance-ids $INSTANCE_ID
        ## Wait for instances to enter 'terminated' state
        echo "Wait for instances to enter terminated state..."
        aws ec2 wait instance-terminated --instance-ids $INSTANCE_ID
        echo "instance terminated"
    fi

    # Delete Key pair
    if [[ -f "backup.txt" ]]; then
        ## Delete key pair
        echo "Delete key pair..."
        aws ec2 delete-key-pair --key-name keypair
        rm -f keypair.pem
        echo "key pair Deleted"
    fi    

    ## Delete custom security group
    if [[ -n "$SECURITY_GROUP_ID" ]]; then
        echo "Delete custom security group..."
        delete_security_group $SECURITY_GROUP_ID
        echo "Security-group deleted"
    fi
}


# Main
setup
comparaison
visualisation
wipe

